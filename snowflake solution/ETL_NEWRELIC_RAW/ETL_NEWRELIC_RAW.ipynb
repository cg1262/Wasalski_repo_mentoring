{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "7g6bp444rsyo6rtxagzo",
   "authorId": "557922832688",
   "authorName": "MTWA",
   "authorEmail": "mtwa@softwaremind.com",
   "sessionId": "b3486383-41a4-4d39-bb35-961cda7d5128",
   "lastEditTime": 1753971891350
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "0a6ab669-1e5c-4978-844d-ec853e241757",
   "metadata": {
    "language": "sql",
    "name": "alter_timezone"
   },
   "outputs": [],
   "source": "ALTER SESSION SET TIMEZONE = 'Europe/London';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3da7e209-d219-40dc-a660-dc997b8bb41b",
   "metadata": {
    "language": "python",
    "name": "variables"
   },
   "outputs": [],
   "source": "try:\n    import pandas as pd\n    import requests\n    import datetime\n    import time\n    \n    from snowflake.snowpark.context import get_active_session\n    session = get_active_session()\n    \n    new_relic_personal_access_token = session.sql(\"SELECT prod.raw.new_relic_secrets()\").collect()[0][0]\n    ACCOUNT_ID = 1801997\n    \nexcept:\n    import pandas as pd\n    import requests\n    import datetime\n    import time\n    import os\n    from dotenv import load_dotenv\n    load_dotenv()\n    new_relic_personal_access_token=os.getenv('new_relic_personal_access_token')\n    ACCOUNT_ID = 1801997\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "newrelic_class",
    "codeCollapsed": false
   },
   "source": "class NewRelic:\n    def __init__(self):\n        self.new_relic_personal_access_token = new_relic_personal_access_token\n        self.ACCOUNT_ID = ACCOUNT_ID\n        self.headers = {'Content-Type': 'application/json', 'API-Key': self.new_relic_personal_access_token}\n        self.API_URL = 'https://api.newrelic.com/graphql'\n        \n        # Oblicz zakres: poprzedni dzień\n        self.today = datetime.date.today()\n        \n        self.yesterday = self.today - datetime.timedelta(days=1)\n        self.start_time = self.yesterday.isoformat()\n        self.end_time = self.today.isoformat()\n        \n        self.current_date = datetime.datetime.now().date()\n        \n        self.nrql_percentage_query = \"SELECT percentage(count(*), WHERE result = 'SUCCESS') FROM SyntheticCheck where monitorName LIKE '%E2E%' and monitorName not like '%uat%' and monitorName not like '%staging%' and monitorName not like '%dev%'and monitorName not like '%training%'  and monitorName not like '%sand%' and monitorName  not like '%test%' and monitorName not like '%sc%' and monitorName not like '%204%' and monitorName not like '%automation%' and monitorName not like '%template%' and monitorName not like '%del%'  and monitorName not like '%maverick%' and monitorName not like '%ctms%' and monitorName not like '%sarep%'  and monitorName not like '%neuron%' and monitorName not like '%sre%' and monitorName not like '%principiabiopharma%' and monitorName not like '%gsk%'and monitorName not like '%acceleron%' and monitorName not like '%immunity%' and monitorName not like '%zs%'   and monitorName not like '%eisai%' and monitorName not like '%canary%' and monitorName not like '%saas%' and monitorName not like '%zeb%' limit 1000 \\\n        SINCE 30 days ago\"\n\n        #vision monthly\n        \n        self.overall_succ_rate_of_vis_us = \"SELECT (filter(UNIQUECOUNT(CorrelationId), WHERE `message` LIKE 'ResponseHandlerApiFunction processed a request for DocumentId:%' AND cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'phlexvision-prod') * 1.0 / filter(UNIQUECOUNT(CorrelationId), WHERE `message` LIKE 'DocumentProcess API received a request for DocumentId:%' AND cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'phlexvision-prod')) * 100 AS 'Success rate of Vision' FROM Log \\\n        SINCE last month UNTIL this month\"\n        \n        self.overall_succ_rate_of_vis_eun = \"SELECT (filter(UNIQUECOUNT(CorrelationId), WHERE `message` LIKE 'ResponseHandlerApiFunction processed a request for DocumentId:%' AND cluster_name = 'aksshared-sharedprod-aks-eun' AND namespace_name = 'phlexvision-prod') * 1.0 / filter(UNIQUECOUNT(CorrelationId), WHERE `message` LIKE 'DocumentProcess API received a request for DocumentId:%' AND cluster_name = 'aksshared-sharedprod-aks-eun' AND namespace_name = 'phlexvision-prod')) * 100 AS 'Success rate of Vision' FROM Log \\\n        SINCE last month UNTIL this month\"\n\n        self.total_doc_entered_vision_us = \"SELECT uniqueCount(CorrelationId) as 'Documents' FROM Log WHERE `message` like 'DocumentProcess API received a request for DocumentId:%' and cluster_name = 'aksshared-sharedprod-aks-use' and namespace_name = 'phlexvision-prod' and applicationName = 'PhlexVision.DocumentProcess.Api' \\\n        since last month until this month\"\n        \n        self.total_doc_entered_vision_eun = \"SELECT uniqueCount(CorrelationId) as 'Documents' FROM Log WHERE `message` like 'DocumentProcess API received a request for DocumentId:%' and cluster_name = 'aksshared-sharedprod-aks-eun' and namespace_name = 'phlexvision-prod' and applicationName = 'PhlexVision.DocumentProcess.Api' \\\n        SINCE last month UNTIL this month\"\n\n        self.stuck_docu_count_eun = \"SELECT count(documentid) AS Documents FROM sqlJobs WHERE jobName = 'stuckDocsInfo' AND (('Production' = 'Production' AND hostname like '%production%') OR ('Production' = 'Non-Production' AND hostname not like '%production%')) AND site in ('zs-test', 'biolinerx-dev', 'ccs-test', 'menarini', 'securabio', 'georgemedicines', 'ccs', 'cromsource-test', 'tgtherapeutics-test', 'zs-dev', 'expresseu-ayr', 'intelliatx', 'dcri-training', 'pacira', 'akouos-dev', 'delivery-sandbox', 'alk-test', 'sitero-dev', 'sumitomosunovion', 'neuron-215-us', 'zebedee', 'lung', 'intercept', 'dots-dev', 'ccs-dev', 'zs', 'mhicc', 'delmr', 'pra-test', 'tgtherapeutics', 'drreddys-test', 'pra-dev', 'galapagos', 'oncopeptides-dev', 'ucl-dev', 'devops-clinical-produs', 'aerogen', 'express-dev', 'dots', 'alexion', 'expresseu-template', 'grailbio', 'acceleron-dev', 'fhic', 'oncopeptides-test', 'devops-clinical-prodeu', 'eisai', 'inozyme', 'oracle-sandbox', 'freseniuskabi-test', 'cromsource-dev', 'freseniuskabi', 'inozyme-dev', 'unitedtherapeutics', 'del217', 'express', 'del218', 'ucl-test', 'dcri-sandbox', 'opstraining', 'pra-uat', 'acceleron-test', 'anavex', 'drreddys', 'expresseu-test', 'delivery-uat', 'purdue2', 'sunovion', 'pra', 'ucl', 'obipharma', 'alk', 'delmr217', 'neuron2-215-eu', 'eisai-test', 'oncologie-test', 'oncopeptides', 'obipharma-test', 'dots-test', 'indivior', 'mundipharma-dev', 'sareptatherapeutics', 'sitero-test', 'fhic-test', 'blueprint', 'aimmune-dev', 'acceleron', 'oncologie', 'expresseu', 'thirdpole', 'aimmune', 'biolinerx-test', 'opstraining-dev', 'freseniuskabi-dev', 'expresseu-dev', 'pacira-dev', 'tmcpharma-test', 'mundipharma', 'inozyme-test', 'trizell', 'karyopharm', 'fhic-dev', 'eisai-dev', 'mmv', 'tgtherapeutics-dev', 'dcri', 'vwave', 'express-test', 'galapagos-dev', 'thirdpole-test', 'turningpoint', 'mhicc-test', 'alk-dev', 'obipharma-dev', 'biolinerx', 'akouos', 'indivior-dev', 'pra-sandbox', 'express-template', 'intelliatx-test', 'cromsource', 'levicept', 'tmcpharma', 'rho', 'akouos-test', 'aimmune-test', 'sitero') AND minutes_ago > 30 AND ProcessingStatus = 'OCR Processing' \\\n        SINCE last month UNTIL this month LIMIT MAX\"\n        \n        self.stuck_docu_count_us = \"SELECT count(documentid) AS Documents FROM sqlJobs WHERE jobName = 'stuckDocsInfo' AND (('Production' = 'Production' AND hostname like '%production%') OR ('Production' = 'Non-Production' AND hostname not like '%production%')) AND site in ('zs-test', 'biolinerx-dev', 'ccs-test', 'menarini', 'securabio', 'georgemedicines', 'ccs', 'cromsource-test', 'tgtherapeutics-test', 'zs-dev', 'expresseu-ayr', 'intelliatx', 'dcri-training', 'pacira', 'akouos-dev', 'delivery-sandbox', 'alk-test', 'sitero-dev', 'sumitomosunovion', 'neuron-215-us', 'zebedee', 'lung', 'intercept', 'dots-dev', 'ccs-dev', 'zs', 'mhicc', 'delmr', 'pra-test', 'tgtherapeutics', 'drreddys-test', 'pra-dev', 'galapagos', 'oncopeptides-dev', 'ucl-dev', 'devops-clinical-produs', 'aerogen', 'express-dev', 'dots', 'alexion', 'expresseu-template', 'grailbio', 'acceleron-dev', 'fhic', 'oncopeptides-test', 'devops-clinical-prodeu', 'eisai', 'inozyme', 'oracle-sandbox', 'freseniuskabi-test', 'cromsource-dev', 'freseniuskabi', 'inozyme-dev', 'unitedtherapeutics', 'del217', 'express', 'del218', 'ucl-test', 'dcri-sandbox', 'opstraining', 'pra-uat', 'acceleron-test', 'anavex', 'drreddys', 'expresseu-test', 'delivery-uat', 'purdue2', 'sunovion', 'pra', 'ucl', 'obipharma', 'alk', 'delmr217', 'neuron2-215-eu', 'eisai-test', 'oncologie-test', 'oncopeptides', 'obipharma-test', 'dots-test', 'indivior', 'mundipharma-dev', 'sareptatherapeutics', 'sitero-test', 'fhic-test', 'blueprint', 'aimmune-dev', 'acceleron', 'oncologie', 'expresseu', 'thirdpole', 'aimmune', 'biolinerx-test', 'opstraining-dev', 'freseniuskabi-dev', 'expresseu-dev', 'pacira-dev', 'tmcpharma-test', 'mundipharma', 'inozyme-test', 'trizell', 'karyopharm', 'fhic-dev', 'eisai-dev', 'mmv', 'tgtherapeutics-dev', 'dcri', 'vwave', 'express-test', 'galapagos-dev', 'thirdpole-test', 'turningpoint', 'mhicc-test', 'alk-dev', 'obipharma-dev', 'biolinerx', 'akouos', 'indivior-dev', 'pra-sandbox', 'express-template', 'intelliatx-test', 'cromsource', 'levicept', 'tmcpharma', 'rho', 'akouos-test', 'aimmune-test', 'sitero') AND minutes_ago > 30 AND ProcessingStatus = 'OCR Processing' \\\n        SINCE last month UNTIL this month LIMIT MAX\"\n\n        #vision daily\n        self.avg_time_successful_docu_us = f\"SELECT SUM(duration) / COUNT(duration) as 'Average Duration (in seconds)' FROM (SELECT filter(MIN(timestamp), WHERE `message` like 'SuccessCallback to % endpoint' and cluster_name = 'aksshared-sharedprod-aks-use' and namespace_name = 'phlexvision-prod' and applicationName = 'PhlexVision.ResponseHandler.Api') / 1000 - filter(MIN(timestamp), WHERE `message` like 'DocumentProcess API received a request for DocumentId: %, File Extension: %, Priority: %' and cluster_name = 'aksshared-sharedprod-aks-use' and namespace_name = 'phlexvision-prod') / 1000 as duration FROM Log WHERE `Duration (in seconds)` != '' FACET CorrelationId LIMIT MAX) WHERE duration > 0 \\\n        SINCE yesterday until today\"\n        \n        self.avg_time_successful_docu_eun = f\"SELECT SUM(duration) / COUNT(duration) as 'Average Duration (in seconds)' FROM (SELECT filter(MIN(timestamp), WHERE `message` like 'SuccessCallback to % endpoint' and cluster_name = 'aksshared-sharedprod-aks-eun' and namespace_name = 'phlexvision-prod' and applicationName = 'PhlexVision.ResponseHandler.Api') / 1000 - filter(MIN(timestamp), WHERE `message` like 'DocumentProcess API received a request for DocumentId: %, File Extension: %, Priority: %' and cluster_name = 'aksshared-sharedprod-aks-eun' and namespace_name = 'phlexvision-prod') / 1000 as duration FROM Log WHERE `Duration (in seconds)` != '' FACET CorrelationId LIMIT MAX) WHERE duration > 0 \\\n        SINCE yesterday until today\"\n\n        # neuron daily\n        self.overall_success_rate_neuron_us = \"SELECT (filter(UNIQUECOUNT(CorrelationId), WHERE `message` LIKE '%MLOpsTrigger: Posted processed data for ReferenceID: % to % at: %' AND cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'neuroncore-prod') * 1.0 / filter(UNIQUECOUNT(CorrelationId), WHERE `message` LIKE '%AxonNeuron: Started posting data to%queue for ReferenceID:%' AND cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'neuroncore-prod')) * 100 AS 'Success rate of Neuron' FROM Log \\\n        SINCE last month UNTIL this month\"\n\n        self.overall_success_rate_neuron_eun = \"SELECT (filter(UNIQUECOUNT(CorrelationId), WHERE `message` LIKE '%MLOpsTrigger: Posted processed data for ReferenceID: % to % at: %' AND cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'neuroncore-prod') * 1.0 / filter(UNIQUECOUNT(CorrelationId), WHERE `message` LIKE '%AxonNeuron: Started posting data to%queue for ReferenceID:%' AND cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'neuroncore-prod')) * 100 AS 'Success rate of Neuron' FROM Log \\\n        SINCE last month UNTIL this month\"\n\n        self.avg_neuron_end_to_end_duration_us = \"SELECT SUM(duration) / COUNT(duration) as 'Overall Duration in Neuron (in seconds)' FROM (SELECT filter(MIN(timestamp), WHERE `message` like '%MLOpsTrigger: Completed Processing data for ReferenceID:%' and cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'neuroncore-prod') / 1000 - filter(MIN(timestamp), WHERE `message` like '%AxonNeuron: Started posting data to % queue for ReferenceID: %' and cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'neuroncore-prod') / 1000 as duration FROM Log WHERE `Duration (in seconds)` != '' FACET CorrelationId LIMIT MAX) WHERE duration > 0 \\\n        SINCE last month UNTIL this month\"\n\n        self.avg_neuron_end_to_end_duration_eun = \"SELECT SUM(duration) / COUNT(duration) as 'Overall Duration in Neuron (in seconds)' FROM (SELECT filter(MIN(timestamp), WHERE `message` like '%MLOpsTrigger: Completed Processing data for ReferenceID:%' and cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'neuroncore-prod') / 1000 - filter(MIN(timestamp), WHERE `message` like '%AxonNeuron: Started posting data to % queue for ReferenceID: %' and cluster_name = 'aksshared-sharedprod-aks-use' AND namespace_name = 'neuroncore-prod') / 1000 as duration FROM Log WHERE `Duration (in seconds)` != '' FACET CorrelationId LIMIT MAX) WHERE duration > 0 \\\n        SINCE last month UNTIL this month\"\n\n        self.documents_stuck_in_ai_all = \"SELECT count(*) as 'AI' FROM stuckDocsInfo WHERE site in ('acacia', 'advil', 'advil219', 'aerogen', 'aerogen-test', 'ajdemo', 'ajtest', 'akouos', 'akouos-test', 'alexion', 'alk', 'anavex', 'archer', 'archer-sponsor', 'arfiauto', 'arfiauto2110', 'artemis', 'autocapybara', 'awawa', 'badb-4', 'bagcpaired', 'bemusponsor', 'bemusponsor-test', 'bemusponsor2110', 'biolinerx', 'blueprint', 'blueprint-dev', 'blueprint-test', 'bobby', 'bonsaiauto2', 'brandon', 'canary', 'ccs', 'cheetah', 'circe', 'clinical-staging', 'clinical-testeu', 'clinical-testus', 'clonedlivetestpaired', 'cromsource', 'dcri', 'dcri-dev', 'dcri-sandbox', 'dcri-test', 'dcri-training', 'del2110', 'del219', 'delivery-sandbox', 'delivery21', 'delivery21saas', 'delmr', 'delmr-test', 'delmr217', 'delmr217-dev', 'delmr217-test', 'delmra', 'delmra-test', 'delmrb', 'dev', 'devops-single-cluster', 'devsecops-dast', 'devsecops-testing', 'do-mysql-percona', 'do-mysql-percona-2', 'dots', 'dots-test', 'drreddys', 'eisai', 'expertservice', 'express', 'expresseu', 'fhic', 'freseniuskabi', 'fsp2110', 'fyndemo', 'galapagos', 'georgemedicines', 'georgemedicines-dev', 'gigantsponsor', 'gloop', 'gold210', 'golddataupdatetest', 'grailbio', 'hackerone', 'hulk', 'hulk2', 'importval170', 'indivior', 'inozyme', 'intelliatx', 'intelliatx-test', 'intercept', 'jakedemo', 'jkrota', 'jkrota-test', 'jokaper', 'jokarep', 'jokatpaas', 'jynfake', 'karyopharm', 'karyopharm-test', 'kazetest', 'klon', 'klon-test', 'krosrep', 'krosreports', 'kw2299', 'lemur-forever', 'lemur-reloaded', 'levicept', 'lifetestsite2110', 'lifetestsite2110-test', 'livetestsite2025', 'livetestsite2025-test', 'livetestsite3-test', 'lublinauto21-10-v1', 'lung', 'mabxience', 'mabxience-test', 'markustmf2131', 'marvel', 'marvel-2', 'marvel-2110', 'marvel-test', 'marvel3', 'massrollout', 'massrolloutgroup2', 'massrolloutgroup2-test', 'maszauto4', 'maszlive2', 'maszlive2-test', 'mavericknew', 'menarini', 'mhicc', 'mhicc-test', 'minotaur', 'miru', 'mmv', 'momzauto1', 'momzauto5', 'momzauto6', 'mundipharma', 'naboo', 'nesstmf', 'neuron-215-us', 'neuron2-215-eu', 'neuron219', 'neurontest01', 'newcreate4', 'newtest', 'nonpairedinstance2110', 'nuerontest02', 'oak', 'obipharma', 'oncopeptides', 'pacira', 'pacira-test', 'passrota', 'pra', 'pra-dev', 'pra-sandbox', 'pra-test', 'pra-uat', 'prdpit-1726-secondary-test', 'prdpit-1748-primary', 'prdpit-1748-primary-test', 'prdpit-1748-secondary', 'prdpit-1748-secondary-test', 'prdpit-1812', 'prdpit-1812-test', 'prdpit-1812dev', 'prdpit853', 'prdpxv-55588', 'processingv2', 'purdue2', 'pw-auto-bulkenv-2111-02', 'pw-auto-env-sampling-2111-02', 'pw-auto-env1-2111-15', 'pw-auto-env2-2110-1', 'pw-auto-env2-21101-29', 'pw-auto-env2-2111-10', 'pw-auto-pq-2', 'pw-auto-reports-2111-01', 'pw-auto-sponsor-2110-5', 'ref-sc', 'reportsdemo', 'reportsdescriptionsfix', 'rho', 'rho-dev', 'rho-test', 'saas2110', 'sareptatherapeutics', 'securabio', 'sharondemo', 'sitero', 'slclust', 'sre-test', 'sumitomosunovion', 'sunovion', 'testeqc', 'testgolddata', 'testsitesingle', 'tgtherapeutics', 'tmcpharma', 'training001', 'trizell', 'tyko21112', 'ucl', 'unitedtherapeutics', 'unitedtherapeutics-test', 'visiontest217', 'visiontestint', 'vwave', 'wedelaut-samp-2111', 'westbound', 'wobopit', 'wronskiauto50', 'wronskiauto50test', 'zebedee', 'zurek') AND (('Production' = 'Production' AND environment like 'production%') OR ('Production' = 'Non-Production' AND environment not like 'production%')) AND ProcessingStatus in ('AI Processing', 'AI Processing (Legacy)') AND minutes_ago > 30 \\\n        SINCE last month UNTIL this month\"\n\n    def get_nrql_percentage(self):\n        time.sleep(15)\n        graphql_query = f\"\"\"\n            {{\n              actor {{\n                account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.nrql_percentage_query}\") {{\n                    results\n                  }}\n                }}\n              }}\n            }}\n            \"\"\"\n            \n        response = requests.post(self.API_URL, json={'query': graphql_query}, headers=self.headers)\n        print(response.json())\n        percentage = response.json().get('data', {}) \\\n                                      .get('actor', {}) \\\n                                      .get('account', {}) \\\n                                      .get('nrql', {}) \\\n                                      .get('results', [{}])[0] \\\n                                      .get('percentage', 0.0)\n            \n        new_relic_data = pd.DataFrame([{'percentage': percentage, 'timestamp_date': self.today}])\n        new_relic_data['percentage'] = new_relic_data['percentage'].astype(float)\n            \n        return new_relic_data\n        # return response.json()\n        \n    def get_overall_succ_rate_of_vis_us(self):\n        time.sleep(15)\n        osr_graphql_query = f\"\"\"\n        {{\n          actor {{\n            account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.overall_succ_rate_of_vis_us}\") {{\n                results\n              }}\n            }}\n          }}\n        }}\n        \"\"\"\n        \n        response = requests.post(self.API_URL, json={'query': osr_graphql_query}, headers=self.headers)\n        print(response.json())\n        success_rate_vision_us = response.json().get('data', {}) \\\n                                  .get('actor', {}) \\\n                                  .get('account', {}) \\\n                                  .get('nrql', {}) \\\n                                  .get('results', [{}])[0] \\\n                                  .get('Success rate of Vision', 0.0)\n        \n        success_rate_vision_us_data = pd.DataFrame([{ 'metrics_name':'Success rate of Vision US', 'value': success_rate_vision_us, 'timestamp_date': self.today}])\n        success_rate_vision_us_data['value'] = success_rate_vision_us_data['value'].astype(float)\n        \n        # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n        \n        # session.write_pandas(new_relic_data,\n        #                          table_name=TEMP_NEWRELIC,\n        #                          auto_create_table=True,\n        #                          overwrite=True,\n        #                          table_type=\"temporary\")\n        return success_rate_vision_us_data\n        \n    def get_overall_succ_rate_of_vis_eun(self):\n        time.sleep(15)\n        osreun_graphql_query = f\"\"\"\n        {{\n          actor {{\n            account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.overall_succ_rate_of_vis_eun}\") {{\n                results\n              }}\n            }}\n          }}\n        }}\n        \"\"\"\n        \n        response = requests.post(self.API_URL, json={'query': osreun_graphql_query}, headers=self.headers)\n        print(response.json())\n        success_rate_vision_eun = response.json().get('data', {}) \\\n                                  .get('actor', {}) \\\n                                  .get('account', {}) \\\n                                  .get('nrql', {}) \\\n                                  .get('results', [{}])[0] \\\n                                  .get('Success rate of Vision', 0.0)\n        \n        success_rate_vision_eun_data = pd.DataFrame([{ 'metrics_name':'Success rate of Vision EUN', 'value': success_rate_vision_eun, 'timestamp_date': self.today}])\n        success_rate_vision_eun_data['value'] = success_rate_vision_eun_data['value'].astype(float)\n        \n        # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n        \n        # session.write_pandas(new_relic_data,\n        #                          table_name=TEMP_NEWRELIC,\n        #                          auto_create_table=True,\n        #                          overwrite=True,\n        #                          table_type=\"temporary\")\n        return success_rate_vision_eun_data\n\n        \n    def get_documents_us_data(self):\n        time.sleep(15)\n        dusd_graphql_query = f\"\"\"\n        {{\n          actor {{\n            account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.stuck_docu_count_us}\") {{\n                results\n              }}\n            }}\n          }}\n        }}\n        \"\"\"\n        \n        response = requests.post(self.API_URL, json={'query': dusd_graphql_query}, headers=self.headers)\n        print(response.json())\n        documents_us = response.json().get('data', {}) \\\n                                  .get('actor', {}) \\\n                                  .get('account', {}) \\\n                                  .get('nrql', {}) \\\n                                  .get('results', [{}])[0] \\\n                                  .get('Documents', 0.0)\n        \n        documents_us_data = pd.DataFrame([{ 'metrics_name':'Documents US', 'value': documents_us, 'timestamp_date': self.today}])\n        documents_us_data['value'] = documents_us_data['value'].astype(float)\n        \n        # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n        \n        # session.write_pandas(new_relic_data,\n        #                          table_name=TEMP_NEWRELIC,\n        #                          auto_create_table=True,\n        #                          overwrite=True,\n        #                          table_type=\"temporary\")\n        return documents_us_data\n    \n    def get_documents_eun_data(self):\n        time.sleep(15)\n        deund_graphql_query = f\"\"\"\n        {{\n          actor {{\n            account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.stuck_docu_count_eun}\") {{\n                results\n              }}\n            }}\n          }}\n        }}\n        \"\"\"\n        \n        response = requests.post(self.API_URL, json={'query': deund_graphql_query}, headers=self.headers)\n        print(response.json())\n        documents_eun = response.json().get('data', {}) \\\n                                  .get('actor', {}) \\\n                                  .get('account', {}) \\\n                                  .get('nrql', {}) \\\n                                  .get('results', [{}])[0] \\\n                                  .get('Documents', 0.0)\n        \n        documents_eun_data = pd.DataFrame([{ 'metrics_name':'Documents EUN', 'value': documents_eun, 'timestamp_date': self.today}])\n        documents_eun_data['value'] = documents_eun_data['value'].astype(float)\n        \n        # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n        \n        # session.write_pandas(new_relic_data,|\n        #                          table_name=TEMP_NEWRELIC,\n        #                          auto_create_table=True,\n        #                          overwrite=True,\n        #                          table_type=\"temporary\")\n        return documents_eun_data\n\n    #vision daily\n    def get_avg_duraiton_us(self):\n        time.sleep(15)      \n        graphql_query = f\"\"\"\n        {{\n          actor {{\n            account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.avg_time_successful_docu_us}\") {{\n                results\n              }}\n            }}\n          }}\n        }}\n        \"\"\"\n        \n        response = requests.post(self.API_URL, json={'query': graphql_query}, headers=self.headers)\n        print(response.json())\n        avg_duraiton_us = response.json().get('data', {}) \\\n                                  .get('actor', {}) \\\n                                  .get('account', {}) \\\n                                  .get('nrql', {}) \\\n                                  .get('results', [{}])[0] \\\n                                  .get('Average Duration (in seconds)', 0.0)\n        \n        avg_duraiton_us_data = pd.DataFrame([{ 'metrics_name':'Average Duration (in seconds) US', 'value': avg_duraiton_us, 'timestamp_date': self.start_time}])\n        # avg_duraiton_us_data['value'] = avg_duraiton_us_data['value'].astype(float)\n        \n        # # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n        \n        # # session.write_pandas(new_relic_data,\n        # #                          table_name=TEMP_NEWRELIC,\n        # #                          auto_create_table=True,\n        # #                          overwrite=True,\n        # #                          table_type=\"temporary\")\n        \n        return avg_duraiton_us_data\n\n    def get_avg_duraiton_eun(self):\n        error_occurred = True  # Start assuming we'll get an error\n        \n        while error_occurred:\n            time.sleep(15)  # Your original delay\n            \n            graphql_query = f\"\"\"\n            {{\n              actor {{\n                account(id: {self.ACCOUNT_ID}) {{\n                      nrql(query: \"{self.avg_time_successful_docu_eun}\") {{\n                    results\n                  }}\n                }}\n              }}\n            }}\n            \"\"\"\n            \n            response = requests.post(self.API_URL, json={'query': graphql_query}, headers=self.headers)\n            response_data = response.json()\n            print(response_data)\n            \n            # Check if we got an error - if 'nrql' is None or if there are errors\n            if (response_data.get('errors') or \n                response_data.get('data', {}).get('actor', {}).get('account', {}).get('nrql') is None):\n                \n                error_occurred = True  # Keep the loop going\n                print(\"Got error, retrying in 15 seconds...\")\n                \n            else:\n                # Success! We got data\n                error_occurred = False  # This will exit the loop\n                \n                avg_duraiton_eun = response_data.get('data', {}) \\\n                                          .get('actor', {}) \\\n                                          .get('account', {}) \\\n                                          .get('nrql', {}) \\\n                                          .get('results', [{}])[0] \\\n                                          .get('Average Duration (in seconds)', 0.0)\n                \n                avg_duraiton_eun_data = pd.DataFrame([{\n                    'metrics_name':'Average Duration (in seconds) EUN', \n                    'value': avg_duraiton_eun, \n                    'timestamp_date': self.start_time\n                }])\n                \n                print(f\"Success! Got value: {avg_duraiton_eun}\")\n                return avg_duraiton_eun_data\n\n\n####################################### Neuron\n        #######################################\n            #######################################\n        \n    def get_success_of_neuron_us(self):\n            time.sleep(15)\n            graphql_query = f\"\"\"\n            {{\n              actor {{\n                account(id: {self.ACCOUNT_ID}) {{\n                      nrql(query: \"{self.overall_success_rate_neuron_us}\") {{\n                    results\n                  }}\n                }}\n              }}\n            }}\n            \"\"\"\n            \n            \n            response = requests.post(self.API_URL, json={'query': graphql_query}, headers=self.headers)\n            print(response.json())\n            success_of_neuron_us = response.json().get('data', {}) \\\n                                      .get('actor', {}) \\\n                                      .get('account', {}) \\\n                                      .get('nrql', {}) \\\n                                      .get('results', [{}])[0] \\\n                                      .get('Success rate of Neuron', 0.0)\n            \n            success_of_neuron_us_data = pd.DataFrame([{ 'metrics_name':'Success rate of Neuron US', 'value': success_of_neuron_us, 'timestamp_date': self.current_date}])\n            success_of_neuron_us_data['value'] = success_of_neuron_us_data['value'].astype(float)\n            \n            # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n            \n            # session.write_pandas(new_relic_data,\n            #                          table_name=TEMP_NEWRELIC,\n            #                          auto_create_table=True,\n            #                          overwrite=True,\n            #                          table_type=\"temporary\")\n            return success_of_neuron_us_data\n            # response.json()\n\n\n    def get_success_of_neuron_eun(self):\n        time.sleep(15)\n        graphql_query = f\"\"\"\n        {{\n          actor {{\n            account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.overall_success_rate_neuron_eun}\") {{\n                results\n              }}\n            }}\n          }}\n        }}\n        \"\"\"\n        \n        response = requests.post(self.API_URL, json={'query': graphql_query}, headers=self.headers)\n        print(response.json())\n        success_of_neuron_eun = response.json().get('data', {}) \\\n                                  .get('actor', {}) \\\n                                  .get('account', {}) \\\n                                  .get('nrql', {}) \\\n                                  .get('results', [{}])[0] \\\n                                  .get('Success rate of Neuron', 0.0)\n        \n        success_of_neuron_eun_data = pd.DataFrame([{ 'metrics_name':'Success rate of Neuron EUN', 'value': success_of_neuron_eun, 'timestamp_date': self.current_date}])\n        success_of_neuron_eun_data['value'] = success_of_neuron_eun_data['value'].astype(float)\n        \n        # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n        \n        # session.write_pandas(new_relic_data,\n        #                          table_name=TEMP_NEWRELIC,\n        #                          auto_create_table=True,\n        #                          overwrite=True,\n        #                          table_type=\"temporary\")\n        return success_of_neuron_eun_data\n        # response.json()\n\n    def get_avg_neuron_e2e_duration_us(self):\n        time.sleep(15)\n        graphql_query = f\"\"\"\n        {{\n          actor {{\n            account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.avg_neuron_end_to_end_duration_us}\") {{\n                results\n              }}\n            }}\n          }}\n        }}\n        \"\"\"\n        \n        \n        response = requests.post(self.API_URL, json={'query': graphql_query}, headers=self.headers)\n        print(response.json())\n        avg_neuron_e2e_duration_us = response.json().get('data', {}) \\\n                                  .get('actor', {}) \\\n                                  .get('account', {}) \\\n                                  .get('nrql', {}) \\\n                                  .get('results', [{}])[0] \\\n                                  .get('Overall Duration in Neuron (in seconds)', 0.0)\n        \n        avg_neuron_e2e_duration_us_data = pd.DataFrame([{ 'metrics_name':'Overall Duration in Neuron (in seconds) US', 'value': avg_neuron_e2e_duration_us, 'timestamp_date': self.current_date}])\n        avg_neuron_e2e_duration_us_data['value'] = avg_neuron_e2e_duration_us_data['value'].astype(float)\n        \n        # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n        \n        # session.write_pandas(new_relic_data,\n        #                          table_name=TEMP_NEWRELIC,\n        #                          auto_create_table=True,\n        #                          overwrite=True,\n        #                          table_type=\"temporary\")\n        return avg_neuron_e2e_duration_us_data\n        # response.json()\n\n    def get_avg_neuron_e2e_duration_eun(self):\n            time.sleep(15)\n            graphql_query = f\"\"\"\n            {{\n              actor {{\n                account(id: {self.ACCOUNT_ID}) {{\n                      nrql(query: \"{self.avg_neuron_end_to_end_duration_eun}\") {{\n                    results\n                  }}\n                }}\n              }}\n            }}\n            \"\"\"\n            \n            response = requests.post(self.API_URL, json={'query': graphql_query}, headers=self.headers)\n            print(response.json())\n            avg_neuron_e2e_duration_eun = response.json().get('data', {}) \\\n                                      .get('actor', {}) \\\n                                      .get('account', {}) \\\n                                      .get('nrql', {}) \\\n                                      .get('results', [{}])[0] \\\n                                      .get('Overall Duration in Neuron (in seconds)', 0.0)\n            \n            avg_neuron_e2e_duration_eun_data = pd.DataFrame([{ 'metrics_name':'Overall Duration in Neuron (in seconds) EUN', 'value': avg_neuron_e2e_duration_eun, 'timestamp_date': self.current_date}])\n            avg_neuron_e2e_duration_eun_data['value'] = avg_neuron_e2e_duration_eun_data['value'].astype(float)\n            \n            # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n            \n            # session.write_pandas(new_relic_data,\n            #                          table_name=TEMP_NEWRELIC,\n            #                          auto_create_table=True,\n            #                          overwrite=True,\n            #                          table_type=\"temporary\")\n            return avg_neuron_e2e_duration_eun_data\n        # response.json()\n\n    def get_documents_stuck_in_ai(self):\n        time.sleep(15)\n        graphql_query = f\"\"\"\n        {{\n          actor {{\n            account(id: {self.ACCOUNT_ID}) {{\n                  nrql(query: \"{self.documents_stuck_in_ai_all}\") {{\n                results\n              }}\n            }}\n          }}\n        }}\n        \"\"\"\n        \n        response = requests.post(self.API_URL, json={'query': graphql_query}, headers=self.headers)\n        print(response.json())\n        documents_stuck_in_ai_value_all = response.json().get('data', {}) \\\n                                  .get('actor', {}) \\\n                                  .get('account', {}) \\\n                                  .get('nrql', {}) \\\n                                  .get('results', [{}])[0] \\\n                                  .get('AI', 0.0)\n        \n        documents_stuck_in_ai_all_data = pd.DataFrame([{ 'metrics_name':'Documents Stuck in AI (Both Prod regions) ALL', 'value': documents_stuck_in_ai_value_all, 'timestamp_date': self.current_date}])\n        documents_stuck_in_ai_all_data['value'] = documents_stuck_in_ai_all_data['value'].astype(float)\n        \n        # TEMP_NEWRELIC = 'TEMP_NEWRELIC'\n        \n        # session.write_pandas(new_relic_data,\n        #                          table_name=TEMP_NEWRELIC,\n        #                          auto_create_table=True,\n        #                          overwrite=True,\n        #                          table_type=\"temporary\")\n        return documents_stuck_in_ai_all_data\n        # response.json()\n\n\n# success_rate_vision_eun\n# Przykład użycia:\n# new_relic_personal_access_token = \"twój_token\"\n# ACCOUNT_ID = \"twoje_account_id\"\napi = NewRelic()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3748e777-e633-496d-8f15-f38f8b2b48e3",
   "metadata": {
    "name": "percentage_success",
    "collapsed": false
   },
   "source": "# Percentage Success"
  },
  {
   "cell_type": "code",
   "id": "ba822b4a-120b-4e38-bd11-de2f33fe581a",
   "metadata": {
    "language": "python",
    "name": "percentage_method_call",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "nrql = api.get_nrql_percentage()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "991aafb1-ca25-493c-a4c0-d161bd9512ea",
   "metadata": {
    "language": "python",
    "name": "percentage_temp_table",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "TEMP_PERCENTAGE_SUCCESS = 'TEMP_PERCENTAGE_SUCCESS'\nsession.write_pandas(nrql,\n                         table_name=TEMP_PERCENTAGE_SUCCESS,\n                         auto_create_table=True,\n                         overwrite=True,\n                         table_type=\"temporary\")\nnrql",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c9440b3-c0bb-48bb-87b3-4f5f4f938e3d",
   "metadata": {
    "language": "sql",
    "name": "percentage_raw_insert",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- -- create or replace table prod.silver.newrelic_api_call\n-- -- (percentage float,\n-- -- timestamp_date date);\n\ninsert into prod.raw.newrelic_api_call\nselect\n\"percentage\",\n\"timestamp_date\"\nfrom TEMP_PERCENTAGE_SUCCESS;\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e39666d7-43f4-48ba-a1e1-dfee679ccc6d",
   "metadata": {
    "language": "sql",
    "name": "percentage_silver_table_insert",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- create or replace table prod.silver.newrelic_api_call as\ninsert overwrite into prod.silver.newrelic_api_call \nwith cte as (select *,\nrow_number() OVER (partition by timestamp_date ORDER BY timestamp_date desc) as rank_asc,\nfrom prod.raw.newrelic_api_call\norder by timestamp_date desc)\nselect percentage, timestamp_date from cte\nwhere rank_asc = 1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1720e035-fc97-4330-8bc3-6d4aefc2f259",
   "metadata": {
    "language": "sql",
    "name": "select_all_percentage",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "select * from prod.silver.newrelic_api_call ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "963d6211-d62b-4e76-a179-4ca74f3f0e5a",
   "metadata": {
    "name": "vision_part",
    "collapsed": false
   },
   "source": "# vision monthly part"
  },
  {
   "cell_type": "code",
   "id": "236b2297-c155-4ff5-82fe-fcec9adfa165",
   "metadata": {
    "language": "python",
    "name": "cell43"
   },
   "outputs": [],
   "source": "success_rate_vision_us_data_df = api.get_overall_succ_rate_of_vis_us()\nsuccess_rate_vision_us_data_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9daecfdc-9e37-4b00-9722-08c045a9d6dd",
   "metadata": {
    "language": "python",
    "name": "cell44"
   },
   "outputs": [],
   "source": "success_rate_vision_eun_data_df = api.get_overall_succ_rate_of_vis_eun()\nsuccess_rate_vision_eun_data_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ff7db01-5af9-407b-8666-7243c240199b",
   "metadata": {
    "language": "python",
    "name": "cell42",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "get_documents_us_data_df = api.get_documents_us_data()\nget_documents_us_data_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d600c406-4174-4f6b-b799-848fc2a10056",
   "metadata": {
    "language": "python",
    "name": "cell41",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "get_documents_eun_data_df = api.get_documents_eun_data()\nget_documents_eun_data_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbc3db74-4f54-4c8d-b626-0e259535114b",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df_monthly = pd.concat([success_rate_vision_us_data_df, success_rate_vision_eun_data_df, get_documents_us_data_df, get_documents_eun_data_df]).reset_index().drop(columns='index')\n# df_monthly['timestamp_date'] = pd.to_datetime(df_monthly['timestamp_date'])\ndf_monthly",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "079ff685-8fa3-49e4-8cfd-ad50c54f19df",
   "metadata": {
    "language": "python",
    "name": "cell22",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "TEMP_VISION_MONTHLY = 'TEMP_VISION_MONTHLY'\n\nsession.write_pandas(df_monthly,\n                         table_name=TEMP_VISION_MONTHLY,\n                         auto_create_table=True,\n                         overwrite=True,\n                         table_type=\"temporary\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1182b816-d1cf-493e-ad6a-72acd2b150b2",
   "metadata": {
    "language": "sql",
    "name": "cell23",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "insert into prod.raw.newrelic_vision_monthly\nselect * from TEMP_VISION_MONTHLY",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "518547ba-a197-405b-9759-c054beeea01d",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\ncreate or replace table  prod.silver.newrelic_vision_monthly as\n\nWITH ranked_data AS (\n    SELECT \"metrics_name\",\n           \"value\",\n           month(\"timestamp_date\") AS month,\n           year(\"timestamp_date\") AS year,\n           \"timestamp_date\",\n           row_number() OVER (PARTITION BY \"metrics_name\" ORDER BY \"timestamp_date\" DESC) AS rank\n    FROM prod.raw.newrelic_vision_monthly\n)\nSELECT \"metrics_name\",\n       \"value\",\n       month,\n       year,\n       month - 1 as covered_month,\n       year as covered_year\n       -- \"timestamp_date\"\nFROM ranked_data\nWHERE rank = 1\nORDER BY \"metrics_name\";\n\nselect * from prod.silver.newrelic_vision_monthly\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a16aba3-607c-411f-a44e-77c24c40abca",
   "metadata": {
    "name": "vision_daily_part",
    "collapsed": false
   },
   "source": "# vision daily part"
  },
  {
   "cell_type": "code",
   "id": "2b2cb316-0dfe-44e7-a755-047263c2e16b",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "avg_duraiton_us_data = api.get_avg_duraiton_us()\navg_duraiton_us_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7abd8d5-0576-49e8-a34c-e80e669a938c",
   "metadata": {
    "language": "python",
    "name": "cell52",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "avg_duraiton_eun_data = api.get_avg_duraiton_eun()\navg_duraiton_eun_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e60e427-493c-43df-84b3-2324e0752826",
   "metadata": {
    "language": "python",
    "name": "cell25",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df_daily = pd.concat([avg_duraiton_us_data, avg_duraiton_eun_data]).reset_index().drop(columns='index')\ndf_monthly['timestamp_date'] = pd.to_datetime(df_monthly['timestamp_date'])\ndf_daily",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d68d1cf1-85ad-420e-9054-2a20af9ac1c5",
   "metadata": {
    "language": "python",
    "name": "cell26",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "TEMP_VISION_DAILY = 'TEMP_VISION_DAILY'\n\nsession.write_pandas(df_daily,\n                         table_name=TEMP_VISION_DAILY,\n                         auto_create_table=True,\n                         overwrite=True,\n                         table_type=\"temporary\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "87020d09-22e7-4140-acfb-d640f9e41fbc",
   "metadata": {
    "language": "sql",
    "name": "cell32",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "insert into prod.raw.newrelic_vision_daily\nselect * from TEMP_VISION_DAILY",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e0da7820-f4bf-464b-85b9-01e5d136d294",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "select * from prod.raw.newrelic_vision_daily",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98991b0c-e530-4643-ba50-e7fa9494bd64",
   "metadata": {
    "language": "sql",
    "name": "cell29",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "create or replace table prod.silver.newrelic_vision as\n\nselect \nmetrics_name, \navg\n    (value) as avg_value, \n-- month(timestamp_date) as month,  \n-- year(timestamp_date) as year,  \n-- timestamp_date,\n--added 01 to the date to keep date formatting in power bi, \ndate\n    (case when \n    length(month(timestamp_date)) = 1\n    then concat(year(timestamp_date), '-','0',month(timestamp_date)-1, '-01')\n    else\n    concat(year(timestamp_date), '-',month(timestamp_date), '-01')\n    end) as covered_month,\nfrom prod.raw.newrelic_vision_daily\ngroup by metrics_name, covered_month;\n\nselect * from prod.silver.newrelic_vision",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "797dfb79-e111-413f-833e-91f3f9b00a46",
   "metadata": {
    "name": "neuron_part",
    "collapsed": false
   },
   "source": "# Neuron part"
  },
  {
   "cell_type": "code",
   "id": "0fd287e0-6e14-463b-97bc-02e09a48be52",
   "metadata": {
    "language": "python",
    "name": "cell51",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "get_success_of_neuron_us = api.get_success_of_neuron_us()\nget_success_of_neuron_us",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0c90df8c-71f1-477c-a51d-f12485a3b396",
   "metadata": {
    "language": "python",
    "name": "cell50",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "get_success_of_neuron_eun = api.get_success_of_neuron_eun()\nget_success_of_neuron_eun",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86eed848-44ea-4678-8677-1112e26bbe6d",
   "metadata": {
    "language": "python",
    "name": "cell49",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "get_avg_neuron_e2e_duration_us = api.get_avg_neuron_e2e_duration_us()\nget_avg_neuron_e2e_duration_us",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "893293e5-dc3f-414f-9e46-cd14c6f13183",
   "metadata": {
    "language": "python",
    "name": "cell48",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "get_avg_neuron_e2e_duration_eun = api.get_avg_neuron_e2e_duration_eun()\nget_avg_neuron_e2e_duration_eun",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "150b9d40-0e68-409c-aecc-d7a039588f9c",
   "metadata": {
    "language": "python",
    "name": "cell46",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "get_documents_stuck_in_ai = api.get_documents_stuck_in_ai()\nget_documents_stuck_in_ai",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7c07997-f190-4fea-affc-3e83789ac9f5",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": "neuron_monthly = pd.concat([get_success_of_neuron_us, get_success_of_neuron_eun, get_avg_neuron_e2e_duration_us, get_avg_neuron_e2e_duration_eun, get_documents_stuck_in_ai]).reset_index().drop(columns='index')\nneuron_monthly",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b8b1431-1254-4769-adee-23d70f33d5dd",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "TEMP_NEURON_MONTHLY = 'TEMP_NEURON_MONTHLY'\n\nsession.write_pandas(neuron_monthly,\n                         table_name=TEMP_NEURON_MONTHLY,\n                         auto_create_table=True,\n                         overwrite=True,\n                         table_type=\"temporary\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c255115f-03db-4fab-b3b9-bd92214d4a78",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "create or replace table prod.raw.neuron_monthly as\nselect * from TEMP_NEURON_MONTHLY;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7471030f-7268-4b96-b3e9-521fba9673c9",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "create or replace table prod.silver.neuron_monthly as\n\nwith cte as (select *,\ndate\n    (case when \n    length(month(\"timestamp_date\")) = 1\n    then concat(year(\"timestamp_date\"), '-','0',month(\"timestamp_date\")-1, '-01')\n    else\n    concat(year(\"timestamp_date\"), '-',month(\"timestamp_date\"), '-01')\n    end) as covered_month,\nfrom prod.raw.neuron_monthly\ngroup by \"metrics_name\", covered_month, \"value\",\"timestamp_date\")\nselect * from cte;\n\nselect * from prod.silver.neuron_monthly\nwhere day(\"timestamp_date\") = 01\n-- row_number() over (partition by \"metrics_name\" order by covered_month desc) as rank,",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b67735da-4701-43a4-b49f-a1b687b68cc1",
   "metadata": {
    "language": "sql",
    "name": "cell7",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}