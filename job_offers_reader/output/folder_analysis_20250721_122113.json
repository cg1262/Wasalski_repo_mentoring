[
  {
    "filename": "Senior Data Engineer (Databricks) - Addepto.pdf",
    "tech_stack": "Azure Databricks SQL Python Big Data Advanced Advanced Advanced Advanced Advanced Airflow Apache Spark Apache Kafka DBT Regular Regular Nice To Have Nice To Have https://justjoin.it/job-offer/addepto-senior-data-engineer-databricks--warszawa-data-df00eb3f 1/5   7/21/25, 10:53 AM Senior Data Engineer (Databricks) - Addepto",
    "job_description": "Seenisorc Draitpa tEnioginneer (Databricks) Online interview Friendly offer Addepto is a leading consulting and technology company specializing in AI and Big Data, helping clients deliver innovative data projects. We partner with top-tier global enterprises and pioneering startups, including Rolls Royce, Continental, Porsche, ABB, and WGU. Our exclusive focus on AI and Big Data has earned us recognition by Forbes as one of the top 10 AI consulting companies. As a Senior Data Engineer, you will have the exciting opportunity to work with a team of technology experts on challenging projects across various industries, leveraging cutting-edge technologies. Here are some of the projects we are seeking talented individuals to join: Design and development of a universal data platform for global aerospace companies. This Azure and Databricks powered initiative combines diverse enterprise and public data sources. The data platform is at the early stages of the development, covering design of architecture and processes as well as giving freedom for technology selection. Data Platform Transformation for energy management association body. This project addressed critical data management challenges, boosting user adoption, performance, and data integrity. The team is implementing a comprehensive data catalog, leveraging Databricks and Apache Spark/PySpark, for simplified data access and governance. Secure integration solutions and enhanced data quality monitoring, utilizing Delta Live Table tests, established trust in the platform. The intermediate result is a user-friendly, secure, and data-driven platform, serving as a basis for further development of ML components. Design of the data transformation and following data ops pipelines for global car manufacturer. This project aims to build a data processing system for both real-time streaming and batch data. We‚Äôll handle data for business uses like process monitoring, analysis, and reporting, while also exploring LLMs for chatbots and data analysis. Key tasks include data cleaning, normalization, and optimizing the data model for performance and accuracy. üöÄ Your main responsibilities: Design and optimize scalable data processing pipelines for both streaming and batch workloads using Big Data technologies such as Databricks, Apache Airflow, and Dagster. Architect and implement end-to-end data platforms, ensuring high availability, performance, and reliability. Lead the development of CI/CD and MLOps processes to automate deployments, monitoring, and model lifecycle management. Develop and maintain applications for aggregating, processing, and analyzing data from diverse sources, ensuring efficiency and scalability. Collaborate with Data Science teams on Machine Learning projects, including text/image analysis, feature engineering, and predictive model deployment. Design and manage complex data transformations using Databricks, DBT, and Apache Airflow, ensuring data integrity and consistency. Translate business requirements into scalable and efficient technical solutions while ensuring optimal performance and data quality. Ensure data security, compliance, and governance best practices are followed across all data pipelines. üéØ What you‚Äôll need to succeed in this role: https://justjoin.it/job-offer/addepto-senior-data-engineer-databricks--warszawa-data-df00eb3f 2/5   7/21/25, 10:53 AM Senior Data Engineer (Databricks) - Addepto At least 5 years of commercial experience implementing, developing, or maintaining Big Data sSyesnteiomrs D. ata Engineer (Databricks) Strong programming skills in Python: writing a clean code, OOP design. Strong SQL skills, including performance tuning, query optimization, and experience with data warehousing solutions. Experience in designing and implementing data governance and data management processes. Deep expertise in Big Data technologies, including Apache Airflow, Dagster, Databricks, and other modern data orchestration and transformation tools. Experience implementing and deploying solutions in cloud environments (with a preference for Azure). Knowledge of how to build and deploy Power BI reports and dashboards for data visualization. Excellent understanding of dimensional data and data modeling techniques. Consulting experience and the ability to guide clients through architectural decisions, technology selection, and best practices. Ability to work independently and take ownership of project deliverables. Familiarity with Spark, Azure Event Hub or Kafka. Master‚Äôs or Ph.D. in Computer Science, Big Data, Mathematics, Physics, or a related field. üéÅ Discover our perks & benefits: Work in a supportive team of passionate enthusiasts of AI & Big Data. Engage with top-tier global enterprises and cutting-edge startups on international projects. Enjoy flexible work arrangements, allowing you to work remotely or from modern offices and coworking spaces. Accelerate your professional growth through career paths, knowledge-sharing initiatives, language classes, and sponsored training or conferences, including a partnership with Databricks, which offers industry-leading training materials and certifications. Choose from various employment options: B2B, employment contracts, or contracts of mandate. Make use of 20 fully paid days off available for B2B contractors and individuals under contracts of mandate. Participate in team-building events and utilize the integration budget. Celebrate work anniversaries, birthdays, and milestones. Access medical and sports packages, eye care, and well-being support services, including psychotherapy and coaching. Get full work equipment for optimal productivity, including a laptop and other necessary devices. With our backing, you can boost your personal brand by speaking at conferences, writing for our blog, or participating in meetups. Experience a smooth onboarding with a dedicated buddy, and start your journey in our friendly, supportive, and autonomous culture. Are you interested in Addepto and would like to join us? Get in touch! We are looking forward to receiving your application. Would you like to know more about us? Visit our website (career page) and social media (Facebook, LinkedIn, Instagram).",
    "extracted_at": "2025-07-21T12:21:12.630396",
    "text_length": 8140
  },
  {
    "filename": "Data Engineer (Databricks) - Addepto.pdf",
    "tech_stack": "Azure Databricks SQL Python Big Data Advanced Advanced Advanced Advanced Advanced Airflow DBT Power BI Dagster Apache Spark Regular Nice To Have Nice To Have Nice To Have Nice To Have https://justjoin.it/job-offer/addepto-data-engineer-databricks--warszawa-data-8e134194 1/4   7/21/25, 10:30 AM Data Engineer (Databricks) - Addepto",
    "job_description": "Daetas Ecnrgiinpeetri o(Dnatabricks) Online interview Friendly offer Addepto is a leading consulting and technology company specializing in AI and Big Data, helping clients deliver innovative data projects. We partner with top-tier global enterprises and pioneering startups, including Rolls Royce, Continental, Porsche, ABB, and WGU. Our exclusive focus on AI and Big Data has earned us recognition by Forbes as one of the top 10 AI companies. As a Data Engineer, you will have the exciting opportunity to work with a team of technology experts on challenging projects across various industries, leveraging cutting-edge technologies. Here are some of the projects we are seeking talented individuals to join: Design and development of a universal data platform for global aerospace companies. This Azure and Databricks powered initiative combines diverse enterprise and public data sources. The data platform is at the early stages of the development, covering design of architecture and processes as well as giving freedom for technology selection. Data Platform Transformation for energy management association body. This project addressed critical data management challenges, boosting user adoption, performance, and data integrity. The team is implementing a comprehensive data catalog, leveraging Databricks and Apache Spark/PySpark, for simplified data access and governance. Secure integration solutions and enhanced data quality monitoring, utilizing Delta Live Table tests, established trust in the platform. The intermediate result is a user-friendly, secure, and data-driven platform, serving as a basis for further development of ML components. Design of the data transformation and following data ops pipelines for global car manufacturer. This project aims to build a data processing system for both real-time streaming and batch data. We‚Äôll handle data for business uses like process monitoring, analysis, and reporting, while also exploring LLMs for chatbots and data analysis. Key tasks include data cleaning, normalization, and optimizing the data model for performance and accuracy. üöÄ Your main responsibilities: Design scalable data processing pipelines for streaming and batch processing using Big Data technologies like Databricks, Airflow and/or Dagster. Contribute to the development of CI/CD and MLOps processes. Develop applications to aggregate, process, and analyze data from diverse sources. Collaborate with the Data Science team on Machine Learning projects, including text/image analysis and predictive model building. Develop and organize data transformations using Databricks/DBT and Apache Airflow. Translate business requirements into technical solutions and ensure optimal performance and quality. üéØ What you‚Äôll need to succeed in this role: At least 3 years of commercial experience implementing, developing, or maintaining Big Data systems. Strong programming skills in Python: writing a clean code, OOP design. Experience in designing and implementing data governance and data management processes. Familiarity with Big Data technologies like Airflow or Dagster, Databricks, Spark and DBT. Experience implementing and deploying solutions in cloud environments (with a preference for Azure). Knowledge of how to build and deploy Power BI reports and dashboards for data visualization. https://justjoin.it/job-offer/addepto-data-engineer-databricks--warszawa-data-8e134194 2/4   7/21/25, 10:30 AM Data Engineer (Databricks) - Addepto Excellent understanding of dimensional data and data modeling techniques. EDxacetall eEnntg cinoememr (uDnaictaatbiorinc kssk)ills and consulting experience with direct interaction with clients. Ability to work independently and take ownership of project deliverables. Master‚Äôs or Ph.D. in Computer Science, Data Science, Mathematics, Physics, or a related field. üéÅ Discover our perks & benefits: Work in a supportive team of passionate enthusiasts of AI & Big Data. Engage with top-tier global enterprises and cutting-edge startups on international projects. Enjoy flexible work arrangements, allowing you to work remotely or from modern offices and coworking spaces. Accelerate your professional growth through career paths, knowledge-sharing initiatives, language classes, and sponsored training or conferences, including a partnership with Databricks, which offers industry-leading training materials and certifications. Choose from various employment options: B2B, employment contracts, or contracts of mandate. Make use of 20 fully paid days off available for B2B contractors and individuals under contracts of mandate. Participate in team-building events and utilize the integration budget. Celebrate work anniversaries, birthdays, and milestones. Access medical and sports packages, eye care, and well-being support services, including psychotherapy and coaching. Get full work equipment for optimal productivity, including a laptop and other necessary devices. With our backing, you can boost your personal brand by speaking at conferences, writing for our blog, or participating in meetups. Experience a smooth onboarding with a dedicated buddy, and start your journey in our friendly, supportive, and autonomous culture. Are you interested in Addepto and would like to join us? Get in touch! We are looking forward to receiving your application. Would you like to know more about us? Visit our website (career page) and social media (Facebook, LinkedIn, Instagram).",
    "extracted_at": "2025-07-21T12:21:13.008317",
    "text_length": 7131
  },
  {
    "filename": "DataBricks Engineer - CRODU.pdf",
    "tech_stack": "English Databricks Python Azure AWS B2 Advanced Advanced Advanced Advanced PySpark ETL Advanced Advanced https://justjoin.it/job-offer/crodu-databricks-engineer-krakow-data-9e044623 1/4   7/21/25, 10:54 AM DataBricks Engineer - CRODU",
    "job_description": "DaetasBcrirckisp Etnigoinneer Online interview Friendly offer üå¥ üëà Forma pracy: fulltime, 100% zdalnie ‚è∞ üëà Start: ASAP üëã Cze≈õƒá! Dla naszego klienta z USA poszukujemy Azure DataBrick Engineer√≥w. Prace dotyczƒÖ dzia≈Ça≈Ñ w obszarach m.in. migracji, zbierania danych i optymalizacji rozwiƒÖza≈Ñ opartych na DataBricks. Klient posiada sta≈Çe zapotrzebowanie na specjalist√≥w. Projekty, kt√≥re prowadzƒÖ przewa≈ºnie sƒÖ kr√≥tkoterminowe (ze sporym prawdopodobie≈Ñstwem na przed≈Çu≈ºenia), a ze wzglƒôdu na sta≈Ço≈õƒá zapotrzebowania klient jest w stanie zaproponowaƒá nowy temat po zako≈Ñczeniu danego projektu. Obecnie poszukiwany jest specjali≈õci do 3 projekt√≥w: - dwa dotyczƒÖ migracji do DataBricks (SageMaker do AWS, oraz wewnƒôtrzna platforma do Azure) - jeden dotyczy prac nad platformƒÖ do analizy danych medycznych (r√≥wnie≈º w oparciu o DataBricks) Dla klienta kluczowe jest obycie w ≈õrodowisku Azure (i/lub) AWS oraz znajomo≈õƒá DataBricks i Apache Spark. Projekty prowadzone przez klienta przede wszystkim dla firm z USA - w wiƒôkszo≈õci przypadk√≥w wymagana jest praca jedynie z niewielkƒÖ zak≈ÇadkƒÖ godzinowƒÖ (np. od 10:00 do 18:00) natomiast jeste≈õmy otwarci na kandydat√≥w preferujƒÖcych pracƒô w innych godzinach. Og√≥lny zakres obowiƒÖzk√≥w: üìç Planowanie prac i dob√≥r odpowiednich narzƒôdzi üìç Integracja baz danych w czasie zbli≈ºonym do rzeczywistego üìç Tworzenie proces√≥w ETL üìç Przeprowadzanie migracji baz danych/ platform/ modelil ML üìç Optymalizacja oraz automatyzacja platform üìç ≈öcis≈Ça wsp√≥≈Çpraca z zespo≈Çem data engineer√≥w, data scientist√≥w oraz architekt√≥w Wymagania: ‚ö° Solidne do≈õwiadczenie w pracy w roli data engineera lub pokrewnych rolach (8+ lat) ‚ö° Bardzo dobra znajomo≈õƒá platformy DataBricks oraz Apache Spark ‚ö° Bardzo dobra znajomo≈õƒá Python ‚ö° Do≈õwiadczenie w przeprowadzaniu migracji danych ‚ö° Do≈õwiadczenie w pracy w ≈õrodowisku Microsoft Azure (np. Data Factory, Synapse, Logic Apps, Data Lake) ‚ö° Do≈õwiadczenie w pracy w ≈õrodowisku AWS ‚ö° Umiejƒôtno≈õci interpersonalne i zespo≈Çowe ‚ö° Umiejƒôtno≈õƒá podejmowania inicjatywy i samodzielno≈õƒá ‚ö° Angielski na poziomie umo≈ºliwiajƒÖcym swobodnƒÖ komunikacjƒô w zespole Mile widziane: ‚ö° Do≈õwiadczenie w projektowaniu i optymalizacji przep≈Çyw√≥w danych za pomocƒÖ, DBT, SSIS, TimeXtender lub podobnych rozwiƒÖza≈Ñ (ETL, ELT) ‚ö° Do≈õwiadczenie z dowolnymi platformami big data lub noSQL (Redshift, Hadoop, EMR, Google Data itp.) Jak dzia≈Çamy i co oferujemy? üéØ Stawiamy na otwartƒÖ komunikacjƒô zar√≥wno w procesie rekrutacji jak i po zatrudnieniu - zale≈ºy nam na klarowno≈õci informacji dotyczƒÖcych procesu i zatrudnienia https://justjoin.it/job-offer/crodu-databricks-engineer-krakow-data-9e044623 2/4   7/21/25, 10:54 AM DataBricks Engineer - CRODU üéØ Do rekrutacji podchodzimy po ludzku, dlatego upraszczamy nasze procesy rekrutacyjne, ≈ºeby by≈Çy mo≈ºliwDiea jtaakB nriacjkpsr oEsntgsiznee ie prrzyjazne kandydatowi üéØ Pracujemy w imiƒô zasady \"remote first\", wiƒôc praca zdalna to u nas norma, a wyjazdy s≈Çu≈ºbowe ograniczamy do minimum üéØ Oferujemy prywatnƒÖ opiekƒô medycznƒÖ (Medicover) oraz kartƒô Multisport dla kontraktor√≥w",
    "extracted_at": "2025-07-21T12:21:13.277281",
    "text_length": 4538
  }
]